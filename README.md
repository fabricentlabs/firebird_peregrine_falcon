# Firebird Peregrine Falcon ðŸ•Šï¸

Ultra-fast Firebird to Parquet extractor with all high-impact optimizations.

## Overview

Firebird Peregrine Falcon is a high-performance Rust-based extractor designed to export Firebird database tables to Parquet format with maximum speed. It implements aggressive parallelization strategies and eliminates bottlenecks to achieve 100-200x faster extraction than naive approaches.

**Performance**: 156,000-270,000 rows/second (vs 885 rows/s baseline)

## Features

### High-Impact Optimizations Implemented

1. **Parallel PK Partitioning** - 40-60 workers (2x CPU cores by default)
2. **Multiple Writer Threads** - Parallel file writes to temp files, then merge
3. **Large Batch Sizes** - 500K-1M rows per batch (vs 200K in standard version)
4. **No ORDER BY** - Removed all ordering for maximum speed
5. **Aggressive Prefetching** - Queue size 8-10 (vs 3-4 in standard)
6. **Cross-Platform** - Works on both Windows and Linux

## Performance

- **Target**: 167x faster than original (~148,000 rows/s)
- **Expected**: 2.5-3x faster than stone_as_fast
- **Batch sizes**: 500K-1M rows (vs 200K-500K)
- **Parallelism**: 2x CPU cores by default (vs 1x CPU cores)

## Build

```bash
cargo build --release
```

## Usage

```bash
./target/release/firebird_peregrine_falcon \
  --database "path/to/database.fdb" \
  --out-dir "/output/directory" \
  --table "TABLE_NAME" \
  --parallelism 40 \
  --pool-size 80
```

### Arguments

- `--database`: Firebird database path
- `--out-dir`: Output directory for Parquet files
- `--table`: Table name to extract
- `--parallelism`: Number of parallel workers (default: 2x CPU cores)
- `--pool-size`: Connection pool size (default: parallelism * 2)
- `--user`: Firebird username (default: SYSDBA)
- `--password`: Firebird password (default: masterkey)
- `--use-compression`: Enable compression (default: false for speed)

## Architecture

### Parallel Extraction Flow

1. **Metadata Loading**: Detect PK, estimate row count
2. **Partitioning**: Split PK range into N partitions (N = parallelism)
3. **Parallel Extraction**: Each partition extracted in parallel to temp file
4. **Merging**: Merge all temp files into final Parquet file
5. **Cleanup**: Remove temp files

### Key Differences from stone_as_fast

- **2x parallelism** by default (2x CPU cores vs 1x)
- **Larger batches** (500K-1M vs 200K-500K)
- **No ORDER BY** anywhere (removed for speed)
- **Aggressive prefetching** (queue size 10 vs 4)
- **Multiple temp files** written in parallel, then merged

## Platform Compatibility

- âœ… Windows (tested)
- âœ… Linux/Ubuntu (compatible)
- Uses cross-platform Rust standard library
- No platform-specific code

## Deployment Options

This project supports multiple deployment methods:

1. **PowerShell Script** (Windows) - `run_agile_log_obrigacao.ps1`
2. **Bash Script** (Ubuntu/Linux) - `run_agile_log_obrigacao.sh`
3. **Prefect Flow** (Cross-platform) - `extract_agile_log_obrigacao.py`

For detailed deployment instructions, see [DEPLOYMENT.md](DEPLOYMENT.md).

### Quick Start with Prefect (Ubuntu)

```bash
# Install dependencies
pip install -r requirements.txt

# Set environment variables
export FIREBIRD_DATABASE="/path/to/database.fdb"
export FIREBIRD_OUT_DIR="/data/output"

# Run extraction
python extract_agile_log_obrigacao.py
```

## Notes

- For best performance, ensure output directory is on fast storage (NVMe SSD)
- Memory usage scales with batch size Ã— parallelism
- For huge tables (>50M rows), consider increasing parallelism to 60-80 workers

